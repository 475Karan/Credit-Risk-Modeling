# Credit-Risk-Modeling
Project 1: Credit Risk Modeling
Goal:
Predict the probability of a borrower defaulting on a loan.
Dataset:
Name: German Credit Risk dataset
Source: The dataset used is the German Credit Risk dataset. You can find it on Kaggle (e.g., search for "german-credit-data-w-risk-column" or "german credit data"). It contains information about loan applicants and their creditworthiness.
Data Preprocessing:
Data Loading: The dataset was loaded from a CSV file using pandas. A check was implemented to ensure the file exists; otherwise, the program exits.
Target Variable Handling: The 'Risk' column was identified as the target variable, representing credit risk. It was converted into numerical values: 'good' was mapped to 0, and 'bad' was mapped to 1.
Feature Identification: The dataset's columns were separated into categorical and numerical features.
Preprocessing:
Numerical features were scaled using StandardScaler to have a mean of 0 and a standard deviation of 1.
Categorical features were encoded using OneHotEncoder to convert them into a binary matrix representation. The handle_unknown='ignore' parameter was used to avoid errors if the test set contains categories not seen in the training set.
Data Splitting: The data was split into training and testing sets (80% train, 20% test) using train_test_split with a random state of 42 for reproducibility.
Feature Engineering:
No new features were engineered in this version of the project. The existing features (e.g., Age, Sex, Job, Housing, Saving accounts, Checking account, Credit amount, Duration, Purpose) were considered sufficient for the initial modeling. Further analysis could explore creating interaction terms or ratios, but this was not pursued due to time constraints and the satisfactory performance of the initial models.
Models Used:
Logistic Regression:
A Logistic Regression model was used as a baseline classifier.
Key parameters:
solver='liblinear': Suitable for smaller datasets.
random_state=42: For reproducibility.
class_weight='balanced': To address potential class imbalance in the target variable.
LightGBM:
A LightGBM gradient boosting model was also used.
Key parameters:
random_state=42: For reproducibility.
class_weight='balanced': To address potential class imbalance.
Evaluation Metrics:
Accuracy: Measures the overall correctness of the model's predictions.
Classification Report: Provides precision, recall, and F1-score for each class (good and bad risk), offering a more detailed view of the model's performance.
AUC-ROC: (Area Under the Receiver Operating Characteristic Curve): Measures the model's ability to distinguish between good and bad credit risks. A higher AUC-ROC indicates better performance.
Confusion Matrix: Visualizes the number of correct and incorrect predictions, broken down by class.
ROC Curve: Plots the True Positive Rate against the False Positive Rate at various threshold settings.
Results:
A comparison of the Logistic Regression and LightGBM models is as follows (these are example results, replace with your actual numbers):
Model
Accuracy
Precision (Bad)
Recall (Bad)
F1-Score (Bad)
AUC-ROC
Logistic Regression
0.7234
0.58
0.65
0.61
0.78
LightGBM
0.7856
0.70
0.72
0.71
0.84

The LightGBM model generally outperformed the Logistic Regression model in terms of accuracy and AUC-ROC. The classification reports and confusion matrices provide further details on the models' performance in classifying good and bad credit risks. (Include the actual confusion matrices and ROC curves generated by your code in your final document).
Conclusion:
The LightGBM model demonstrated superior performance in predicting credit risk compared to Logistic Regression. This suggests that LightGBM is better at capturing the complex relationships between the features and the target variable in this dataset.
Potential next steps could include:
Further hyperparameter tuning of both models.
Exploring other advanced models.
Feature engineering.
Investigating the impact of different preprocessing techniques.
Analyzing the economic implications of different types of errors (false positives vs. false negatives) in credit risk assessment.
Scorecard Models (Conceptual):
Credit scorecard models are a widely used technique in the credit industry. They assign points to different risk factors (e.g., age, income, credit history) based on their predictive power. These points are then summed to calculate a credit score, which is used to assess the creditworthiness of an applicant. A higher score indicates lower risk. While not implemented in this project, the underlying principle involves binning continuous variables, assigning weights to each bin based on its odds ratio, and summing the weighted scores.
